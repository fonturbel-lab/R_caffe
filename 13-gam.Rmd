---
title: "13 - Generalized Additive Models"
author: "Francisco E. Fonturbel"
date: "2/November/2022"
output: 
  html_document:
    includes:
        after_body: footer.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

# Non-linear models

Generalized Linear Models relax some assumptions but assume that predictor variables have a **linear** relationship with the response variable. But what if our response variable is not linear? Fortunately, we have a non-linear approach called Generalized Additive Models, in which we can use linear and non-linear predictors in the same model.

To illustrate this lesson, we will use country-scale data from the United Nations report in education and human development.

```{r data}
library(mgcv)
library(ggplot2)
source("multiplot.R")

data<-read.csv("data/13_UN_data.csv", 
                     header=TRUE, 
                     sep=",",
                     dec=".",
                     na.strings="NA")
attach(data)

##Some ggplot2 grooming
My_Theme = theme(
  axis.title.x = element_text(size = 20,face="bold"),
  axis.text.x = element_text(size = 16),
  axis.text.y = element_text(size = 16),
  axis.title.y = element_text(size = 20,face="bold"),
  legend.text = element_text(size = 14),
  legend.title = element_text(size = 14,face="bold"),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_rect(fill = "white"))
```

How our variables look like? Let's use `ggplot` to make some awesome plots:

```{r plots, echo=TRUE, message=FALSE, warning=FALSE}
a1<-ggplot(data=data, aes(x=HDI, y=Overall)) +
  geom_point(color="red") +
  geom_smooth(size=1, span = 0.5, method = "loess") + labs(x="Education", y="Overall") +
  theme_classic() +
  My_Theme
a2<-ggplot(data=data, aes(x=Edu, y=Overall)) +
  geom_point(color="red") +
  geom_smooth(size=1, span = 0.5, method = "loess") + labs(x="HDI", y="Overall") +
  theme_classic() +
  My_Theme
a3<-ggplot(data=data, aes(x=Health, y=Overall)) +
  geom_point(color="red") +
  geom_smooth(size=1, span = 0.5, method = "loess") + labs(x="Health", y="Overall") +
  theme_classic() +
  My_Theme
a4<-ggplot(data=data, aes(x=Health, y=Income)) +
  geom_point(color="red") +
  geom_smooth(size=1, span = 0.5, method = "loess") + labs(x="Income", y="Overall") +
  theme_classic() +
  My_Theme
a5<-ggplot(data=data, aes(x=Health, y=Interest)) +
  geom_point(color="red") +
  geom_smooth(size=1, span = 0.5, method = "loess") + labs(x="Interest", y="Overall") +
  theme_classic() +
  My_Theme
a6<-ggplot(data=data, aes(x=Health, y=Support)) +
  geom_point(color="red") +
  geom_smooth(size=1, span = 0.5, method = "loess") + labs(x="Support", y="Overall") +
  theme_classic() +
  My_Theme
multiplot(a1, a2, a3, a4, a5, a6, cols = 2)
```

As we can see, those predictor variables are not quite linear...

## Comparing GLM vs GAM performance

Linear model:

```{r glm}
mod_lm = gam(Overall ~ Income, data = data)
summary(mod_lm)
```

Non-linear model:

```{r gam}
mod_gam1 = gam(Overall ~ s(Income, bs = "cr"), data = data)
summary(mod_gam1)

plot(mod_gam1)
```

**Linear model performance:**

```{r lmp}
AIC(mod_lm)
summary(mod_lm)$r.sq
```

**Non-linear model performance:**

```{r nlmp}
AIC(mod_gam1)
summary(mod_gam1)$r.sq
```

As we can see, the GAM model has a better performance than the GLM model. Let's make a formal test using `anova`:

```{r anova}
anova(mod_lm, mod_gam1, test = "Chisq")
```

Well, the GAM model is significantly better than the GLM model.


## Using multiple predictors

As in GLM, we can fit multiple predictors in GAM, let's see an example:

```{r gam2}
mod_gam2 = gam(Overall ~ s(Income) + s(Edu) + s(Health), data = data)
summary(mod_gam2)
```


## Final thoughts

Relaxing other assumptions allow us to properly analyze other kind of data. On the one hand, zero-inflated models allow to fit Poisson and negative binomial GLMs when we have an excess of zeroes in out dataset, correcting the estimates and P-values. On the other hand, GEE work in a similar way than GLMs but are able to operate with heterogeneous variances, which represent a major assumption violation in most linear models.


## Session

```{r session, echo=TRUE}
sessionInfo()
```