---
title: "10 - Model averaring and regression trees"
author: "Francisco E. Fonturbel"
date: "01/September/2022"
output: 
  html_document:
    includes:
        after_body: footer.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

## Dealing with multiple variables at once

Now that we learned how to conduct multivariate regressions, it's easy to be tempted to include so many variables in our models, which creates new problems (e.g., multicollinearity caused by introducing redundant variables into the models). Fortunately, there are many approaches to deal with this kind of situations. Here we will explore model averaging and regression trees.

## Model averaging

Once we fit a model with two or more variables, we may wonder if all of those variables are important in explaining our response variable, or only a subset of those variables are really important and the remaining ones can be safely discarded. I recommend you to take a look to Burnham & Anderson's book on this matter, which is highly enlightning about this.

To illustrate this point, we will use data from [Cordero et al. (2020)](https://www.mdpi.com/882552)

```{r data}
library(mgcv)
library(lme4)
library(MASS)
library(lmerTest)
library(pbkrtest)
library(MuMIn)
library(corrplot)
library(ggpubr)
library(PairedData)
library(plyr)
library(ggplot2)
library(GGally)

data<-read.table("data/10_data_threat.txt", 
                     header=TRUE, 
                     sep="\t",
                     dec=",",
                     na.strings="NA")
attach(data)
head(data)
```

We collected a huge dataset on several economic and educative metrics for 138 countries around the world and related them to the proportion of threatened species of the major vertebrate groups (I recommend you to read the paper using the link provided above if you are interested in this subject).

First we should examine how our variables are correlated:

```{r correlation, eval=TRUE, echo=TRUE, fig.width=12, fig.height=12}

My_Theme = theme(
  plot.caption = element_text(size = 14),
  legend.text = element_text(size = 14))

source("multiplot.R")
mm<-stats::cor(data[,4:16], use="pairwise.complete.obs")
corcov<-ggcorr(data = NULL, cor_matrix = cor(mm, use = "everything")) +
  My_Theme
        
multiplot(corcov)
```

As expected, we have a lot of variables and some of them are highly correlated.

Before start making models, we should transform our response variables as they are proportions:

```{r transf, eval=TRUE, echo=TRUE, fig.width=12, fig.height=9}

#Data transforming for proportions
tmamm07<-log(prop_thr_mammals07/(1-prop_thr_mammals07))
tmamm17<-log(prop_thr_mammals17/(1-prop_thr_mammals17))
tbirds07<-log(prop_thr_birds07/(1-prop_thr_birds07))
tbirds17<-log(prop_thr_birds17/(1-prop_thr_birds17))
trept07<-log(prop_thr_reptiles07/(1-prop_thr_reptiles07))
trept17<-log(prop_thr_reptiles17/(1-prop_thr_reptiles17))
tamph07<-log(prop_thr_amphibians07/(1-prop_thr_amphibians07))
tamph17<-log(prop_thr_amphibians17/(1-prop_thr_amphibians17))
tverteb07<-log(prop_thr_vertebrates07/(1-prop_thr_vertebrates07))
tverteb17<-log(prop_thr_vertebrates17/(1-prop_thr_vertebrates17))

#making some transformation por percentage of protected land first
perc_prot_land<-log(perc_prot_land+1)

```


## Final thoughts

Multiple linear regression works in the same way than linear regression with a single variable. We rely on the same assumptions but we have the flexibility to add several continuous variables to explain our response variable.


## Session

```{r session, echo=TRUE}
sessionInfo()
```