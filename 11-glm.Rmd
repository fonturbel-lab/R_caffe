---
title: "11 - Generalized Linear Models and data distributions"
author: "Francisco E. Fonturbel"
date: "14/September/2022"
output: 
  html_document:
    includes:
        after_body: footer.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

## Relaxing model assumptions... open many analysis possibilities

In the first part of this brief R course, we dealt with different tests that have similar assumptions (e.g., normality, homocedasticity, independence) but we know well that in real life many of those assumptions cannot be met using biological data. Also, we had some models (e.g., ANOVA) that use categorical predictors and others (e.g., linear regression) that use continuous predictors, but we were unable to mix both types of predictors in one model. Also, a major limitation of those _basic_ models is that we are stuck with a normal (= Gaussian) data distribution. But fortunately there are other options.

## Beyond the Gaussian distribution

Once we fit a model with two or more variables, we may wonder if all of those variables are important in explaining our response variable, or only a subset of those variables are really important and the remaining ones can be safely discarded. I recommend you to take a look to Burnham & Anderson's book on this matter, which is highly enlightning about this.

To illustrate this point, we will use data from [Cordero et al. (2020)](https://www.mdpi.com/882552)

```{r data}
library(mgcv)
library(lme4)

data<-read.table("data/10_data_threat.txt", 
                     header=TRUE, 
                     sep="\t",
                     dec=",",
                     na.strings="NA")
attach(data)
head(data)
```


## Generalized Linear Models in action

AAA


## Final thoughts

aaa


## Session

```{r session, echo=TRUE}
sessionInfo()
```